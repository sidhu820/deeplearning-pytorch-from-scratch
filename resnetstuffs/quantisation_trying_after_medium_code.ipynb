{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935fa576-4e4b-45c4-bfd9-80026f49bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import torchvision.models.quantization as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0620067-01aa-45ad-9118-88be44927bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c01274-6d2c-41aa-b5aa-278a1e7b20ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=16, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9293c422-47a5-4475-a648-cb1a56485460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tricus/task1/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tricus/task1/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cad47a8-5ad0-46a0-bed0-e0de6b294531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quantized_model(model):\n",
    "    # Iterate through all modules in the model\n",
    "    for module in model.modules():\n",
    "        # Check if the module belongs to the quantized namespace\n",
    "        if isinstance(module, (torch.nn.quantized.Conv2d, torch.nn.quantized.Linear)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2d24628-f865-4984-8c54-0dcd6003a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8b210a-03c3-4909-ba5d-bf8fa24f90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :0, loss :0.6033951090693473\n",
      "epochs :1, loss :0.14049217935204505\n",
      "epochs :2, loss :0.059439822801947595\n",
      "epochs :3, loss :0.029434860871732235\n",
      "epochs :4, loss :0.01681124524921179\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        running_loss /= len(dataloader.dataset) / inputs.size(0)\n",
    "        print(f'epochs :{epoch}, loss :{running_loss}')\n",
    "train(model, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9edf0c27-964c-464d-bd12-53784ec27445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e44997-67f3-4654-99b4-1fcb398f7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_dataloader(dataloader, start, end):\n",
    "    sliced_data = []\n",
    "    current_index = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        batch_size = inputs.size(0)\n",
    "        if current_index + batch_size > start:\n",
    "            # Find the start index within the current batch\n",
    "            start_idx = max(start - current_index, 0)\n",
    "            # Find the end index within the current batch\n",
    "            end_idx = min(end - current_index, batch_size)\n",
    "            sliced_inputs = inputs[start_idx:end_idx]\n",
    "            sliced_labels = labels[start_idx:end_idx]\n",
    "            sliced_data.append((sliced_inputs, sliced_labels))\n",
    "            if current_index + batch_size >= end:\n",
    "                break\n",
    "        current_index += batch_size\n",
    "    return sliced_data\n",
    "\n",
    "# Example usage: Slice the first 150 images from the DataLoader\n",
    "sliced_data = slice_dataloader(trainloader, start=0, end=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c46bf8e-06bf-4644-a86a-858e291119fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('size (KB) :',os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e61349-524d-4146-9545-63a8cf4477fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 22\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in sliced_data:\n",
    "    print(f\"Batch size: {inputs.size(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53497915-2cd4-4c48-a25d-afb0ae087dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of fp32 on the test images: 90.66666666666667% \n",
      "size (KB) : 46836.408\n"
     ]
    }
   ],
   "source": [
    "score = test(model, sliced_data)\n",
    "print('Accuracy of fp32 on the test images: {}% '.format(score))\n",
    "\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a20e5625-be75-4a50-b50c-c8fbe55d1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae54bee1-467b-4575-8367-d42f23258c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model = copy.deepcopy(model)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "quant_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39c0409b-48a3-467c-af85-6ea5a27c8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(quant_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d8d4a26-af1b-4b65-955a-7a6ec98f3bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableResNet(\n",
       "  (conv1): Conv2d(\n",
       "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (add_relu): FloatFunctional(\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(\n",
       "    in_features=512, out_features=1000, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model.qconfig = torch.quantization.default_qconfig\n",
    "torch.quantization.prepare(quant_model, inplace=True) # Inserting Observers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8360cb3-da25-4d3c-9083-039e5462d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(quant_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c27a2022-adde-408f-8154-25e1e0f8cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "caliberate_data = slice_dataloader(trainloader, start=160, end=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9827dfb0-70ea-4df2-89a7-ff0f62cd45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in caliberate_data:\n",
    "    print(f\"Batch size: {inputs.size(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1137fc8-204f-438a-a8ee-ddac25f4ea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.41666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(quant_model, caliberate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec43b119-ca2e-4f53-a039-da0e170600b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(quant_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f9cd693-0b30-49d5-a156-199a18e8c2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableResNet(\n",
       "  (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.12996891140937805, zero_point=64, padding=(3, 3), bias=False)\n",
       "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.12118503451347351, zero_point=78, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07170393317937851, zero_point=78, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.038576602935791016, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1044996827840805, zero_point=76, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0653059333562851, zero_point=63, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.050920285284519196, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.10253451019525528, zero_point=68, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.04779205098748207, zero_point=68, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.06266915053129196, zero_point=57, bias=False)\n",
       "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.03322543948888779, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.06459851562976837, zero_point=70, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.03385411947965622, zero_point=67, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.04494654759764671, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.09302785247564316, zero_point=70, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.052095554769039154, zero_point=74, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.02227053977549076, zero_point=68, bias=False)\n",
       "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.0365685299038887, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.055970560759305954, zero_point=65, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.030317101627588272, zero_point=68, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.033601582050323486, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.048873018473386765, zero_point=64, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.03018638677895069, zero_point=57, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.027820061892271042, zero_point=64, bias=False)\n",
       "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.044272907078266144, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.059192005544900894, zero_point=74, padding=(1, 1), bias=False)\n",
       "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.020229889079928398, zero_point=55, padding=(1, 1), bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add_relu): QFunctional(\n",
       "        scale=0.18025583028793335, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.33822980523109436, zero_point=30, qscheme=torch.per_tensor_affine)\n",
       "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.convert(quant_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c0f8989-82ee-4199-9e7d-8b972fe14a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the model quantized?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is the model quantized? \", is_quantized_model(quant_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5ae4c14-aaff-4a63-90aa-4707bb683ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 48\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 60\n"
     ]
    }
   ],
   "source": [
    "final_testing = slice_dataloader(trainloader, start=400, end=700)\n",
    "for inputs, labels in final_testing:\n",
    "    print(f\"Batch size: {inputs.size(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e47a9fdf-cc36-4158-b151-56569d18e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 87.66666666666667% - INT8\n",
      "size (KB) : 11829.916\n"
     ]
    }
   ],
   "source": [
    "score = test(quant_model, final_testing)\n",
    "print('Accuracy : {}% - INT8'.format(score))\n",
    "\n",
    "print_size_of_model(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8268df-9e23-4c64-b5b4-a9b50b610713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f788d7-7529-47a2-8da8-bc164613c209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (task1)",
   "language": "python",
   "name": "task1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
