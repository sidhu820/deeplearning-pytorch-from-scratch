{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OUPGi7pVrF1f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models.quantization as models\n",
    "import torch.nn.utils.prune as prune\n",
    "import os\n",
    "import copy\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fd0pWe0xvFjm"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float, end : float, device : torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f' Train time :{total_time:.3f}')\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2dKQfHeZvLyg"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1SIK2QaVvT0d",
    "outputId": "eedb6fea-a0f1-4754-a872-2a838eb60df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=16, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JX5VDNYxvXRO",
    "outputId": "c4077e5b-4224-4371-9a66-0e3ae9982538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X3Lf3KHYva3K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample= None, stride= 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.expansion = 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size= 3, stride= stride, padding= 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size= 3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        # x += identity\n",
    "        x = self.skip_add.add(x, identity)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, BasicBlock, layers, image_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride= 2, padding= 1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, layers[0], out_channels= 64, stride= 1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, layers[1], out_channels= 128, stride= 2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, layers[2], out_channels= 256, stride= 2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, layers[3], out_channels= 512, stride= 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_layer(self, BasicBlock, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels , kernel_size= 1, stride= stride),\n",
    "                                               nn.BatchNorm2d(out_channels))\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet18(img_channels= 3, num_classes= 100):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], img_channels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypw4u8suTmtY",
    "outputId": "55650918-8733-44a9-fa3b-db85d8b86e6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4lcF7tzGNpX",
    "outputId": "a236414f-121e-43d7-cdc4-52f2399b45a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1          [-1, 3, 224, 224]               0\n",
      "            Conv2d-2         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "         Identity-11           [-1, 64, 56, 56]               0\n",
      "             ReLU-12           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "             ReLU-16           [-1, 64, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "         Identity-19           [-1, 64, 56, 56]               0\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "             ReLU-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "           Conv2d-27          [-1, 128, 28, 28]           8,320\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "         Identity-29          [-1, 128, 28, 28]               0\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-31          [-1, 128, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "         Identity-37          [-1, 128, 28, 28]               0\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "           Conv2d-43          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-44          [-1, 256, 14, 14]             512\n",
      "           Conv2d-45          [-1, 256, 14, 14]          33,024\n",
      "      BatchNorm2d-46          [-1, 256, 14, 14]             512\n",
      "         Identity-47          [-1, 256, 14, 14]               0\n",
      "             ReLU-48          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-49          [-1, 256, 14, 14]               0\n",
      "           Conv2d-50          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-51          [-1, 256, 14, 14]             512\n",
      "             ReLU-52          [-1, 256, 14, 14]               0\n",
      "           Conv2d-53          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-54          [-1, 256, 14, 14]             512\n",
      "         Identity-55          [-1, 256, 14, 14]               0\n",
      "             ReLU-56          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-57          [-1, 256, 14, 14]               0\n",
      "           Conv2d-58            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-59            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-60            [-1, 512, 7, 7]               0\n",
      "           Conv2d-61            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-62            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-63            [-1, 512, 7, 7]         131,584\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "         Identity-65            [-1, 512, 7, 7]               0\n",
      "             ReLU-66            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-67            [-1, 512, 7, 7]               0\n",
      "           Conv2d-68            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-69            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-70            [-1, 512, 7, 7]               0\n",
      "           Conv2d-71            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-72            [-1, 512, 7, 7]           1,024\n",
      "         Identity-73            [-1, 512, 7, 7]               0\n",
      "             ReLU-74            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-75            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-76            [-1, 512, 1, 1]               0\n",
      "           Linear-77                  [-1, 100]          51,300\n",
      "      DeQuantStub-78                  [-1, 100]               0\n",
      "================================================================\n",
      "Total params: 11,232,612\n",
      "Trainable params: 11,232,612\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 69.68\n",
      "Params size (MB): 42.85\n",
      "Estimated Total Size (MB): 113.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size= (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0Csz4_1J6fm",
    "outputId": "50fad2e7-1f46-4fc4-fe7e-4aa194191040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer1.0\n",
      "layer1.0.conv1\n",
      "layer1.0.bn1\n",
      "layer1.0.conv2\n",
      "layer1.0.bn2\n",
      "layer1.0.relu\n",
      "layer1.0.skip_add\n",
      "layer1.0.skip_add.activation_post_process\n",
      "layer1.1\n",
      "layer1.1.conv1\n",
      "layer1.1.bn1\n",
      "layer1.1.conv2\n",
      "layer1.1.bn2\n",
      "layer1.1.relu\n",
      "layer1.1.skip_add\n",
      "layer1.1.skip_add.activation_post_process\n",
      "layer2\n",
      "layer2.0\n",
      "layer2.0.conv1\n",
      "layer2.0.bn1\n",
      "layer2.0.conv2\n",
      "layer2.0.bn2\n",
      "layer2.0.relu\n",
      "layer2.0.identity_downsample\n",
      "layer2.0.identity_downsample.0\n",
      "layer2.0.identity_downsample.1\n",
      "layer2.0.skip_add\n",
      "layer2.0.skip_add.activation_post_process\n",
      "layer2.1\n",
      "layer2.1.conv1\n",
      "layer2.1.bn1\n",
      "layer2.1.conv2\n",
      "layer2.1.bn2\n",
      "layer2.1.relu\n",
      "layer2.1.skip_add\n",
      "layer2.1.skip_add.activation_post_process\n",
      "layer3\n",
      "layer3.0\n",
      "layer3.0.conv1\n",
      "layer3.0.bn1\n",
      "layer3.0.conv2\n",
      "layer3.0.bn2\n",
      "layer3.0.relu\n",
      "layer3.0.identity_downsample\n",
      "layer3.0.identity_downsample.0\n",
      "layer3.0.identity_downsample.1\n",
      "layer3.0.skip_add\n",
      "layer3.0.skip_add.activation_post_process\n",
      "layer3.1\n",
      "layer3.1.conv1\n",
      "layer3.1.bn1\n",
      "layer3.1.conv2\n",
      "layer3.1.bn2\n",
      "layer3.1.relu\n",
      "layer3.1.skip_add\n",
      "layer3.1.skip_add.activation_post_process\n",
      "layer4\n",
      "layer4.0\n",
      "layer4.0.conv1\n",
      "layer4.0.bn1\n",
      "layer4.0.conv2\n",
      "layer4.0.bn2\n",
      "layer4.0.relu\n",
      "layer4.0.identity_downsample\n",
      "layer4.0.identity_downsample.0\n",
      "layer4.0.identity_downsample.1\n",
      "layer4.0.skip_add\n",
      "layer4.0.skip_add.activation_post_process\n",
      "layer4.1\n",
      "layer4.1.conv1\n",
      "layer4.1.bn1\n",
      "layer4.1.conv2\n",
      "layer4.1.bn2\n",
      "layer4.1.relu\n",
      "layer4.1.skip_add\n",
      "layer4.1.skip_add.activation_post_process\n",
      "avgpool\n",
      "fc\n",
      "quant\n",
      "dequant\n"
     ]
    }
   ],
   "source": [
    "for layers, _ in model.named_modules():\n",
    "  print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5m_X9Hcj5xj1"
   },
   "outputs": [],
   "source": [
    "def calculate_time(start:float, end : float, device : torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f' Evaluation time :{total_time:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cK_B7JRO7b7v"
   },
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('size (KB) :',os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "27ar8Bslw1mL"
   },
   "outputs": [],
   "source": [
    "def prune_model(model, pruning_rate=0.3):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "\n",
    "            # Applying unstructured L1 norm pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_rate)\n",
    "\n",
    "            prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-qKhq9JJ0hwJ"
   },
   "outputs": [],
   "source": [
    "def count_nonzero_params(model):\n",
    "    # non_zero_count = 0\n",
    "    # for param in model.parameters():\n",
    "    #     non_zero_count += torch.count_nonzero(param).item()\n",
    "    print(\"The number of non-zero parameters :\", sum(p.numel() for p in model.parameters()))\n",
    "    zero_count = 0\n",
    "    for param in model.parameters():\n",
    "        zero_count += torch.sum(param == 0).item()\n",
    "    \n",
    "    print(\"The number of zero parameters :\", zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U29-P1NlSYza"
   },
   "outputs": [],
   "source": [
    "def slice_dataloader(dataloader, start, end):\n",
    "    sliced_data = []\n",
    "    current_index = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        batch_size = inputs.size(0)\n",
    "        if current_index + batch_size > start:\n",
    "            # Find the start index within the current batch\n",
    "            start_idx = max(start - current_index, 0)\n",
    "            # Find the end index within the current batch\n",
    "            end_idx = min(end - current_index, batch_size)\n",
    "            sliced_inputs = inputs[start_idx:end_idx]\n",
    "            sliced_labels = labels[start_idx:end_idx]\n",
    "            sliced_data.append((sliced_inputs, sliced_labels))\n",
    "            if current_index + batch_size >= end:\n",
    "                break\n",
    "        current_index += batch_size\n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kFti7vrKw9cO"
   },
   "outputs": [],
   "source": [
    "def train(model,dataloader, device):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "  epochs = 4\n",
    "  for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      model.train()\n",
    "      for i, data in enumerate(dataloader, 0):\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          model = model.to(device)\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
    "\n",
    "      if (epoch + 1) % 2 == 0:\n",
    "          print(f'Pruning after epoch {epoch + 1}')\n",
    "          prune_model(model, pruning_rate=0.1)\n",
    "          print('Pruning done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hDrJshGYzuLt"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "  start = timer()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      for data in dataloader:\n",
    "          inputs, labels = data\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          model = model.to(device)\n",
    "          outputs = model(inputs)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "      print(f'Accuracy of the network on the {total} test images: %d %%' % (100 * correct / total))\n",
    "  end = timer()\n",
    "  calculate_time(start, end, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "jH9hVSO2gGht",
    "outputId": "141f82c6-b67a-4a30-a794-6a92bd5d9368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero parameters : 11232612\n",
      "The number of zero parameters : 4800\n"
     ]
    }
   ],
   "source": [
    "count_nonzero_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('resnetown.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero parameters : 11232612\n",
      "The number of zero parameters : 1121811\n"
     ]
    }
   ],
   "source": [
    "count_nonzero_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_testing = slice_dataloader(testloader, 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 80 %\n",
      " Evaluation time :17.787\n"
     ]
    }
   ],
   "source": [
    "test(model, for_testing, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_quant_model = torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 80 %\n",
      " Evaluation time :18.526\n"
     ]
    }
   ],
   "source": [
    "test(model, for_testing, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size (KB) : 45015.85\n",
      "size (KB) : 44863.277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(model), print_size_of_model(dynamic_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_quant_model = copy.deepcopy(dynamic_quant_model)\n",
    "\n",
    "# state_dict = dynamic_quant_model.state_dict()\n",
    "# static_quant_model.load_state_dict(state_dict).to('cpu')\n",
    "dynamic_quant_model.eval()\n",
    "modules_to_fuse = modules_to_fuse = [\n",
    "    ['conv1','bn1','relu'],\n",
    "    ['layer1.0.conv1','layer1.0.bn1'],\n",
    "    ['layer1.0.conv2','layer1.0.bn2','layer1.0.relu'],\n",
    "    ['layer1.1.conv1','layer1.1.bn1'],\n",
    "    ['layer1.1.conv2','layer1.1.bn2','layer1.1.relu'],\n",
    "    ['layer2.0.conv1','layer2.0.bn1'],\n",
    "    ['layer2.0.conv2','layer2.0.bn2','layer2.0.relu'],\n",
    "    ['layer2.0.identity_downsample.0','layer2.0.identity_downsample.1'],\n",
    "    ['layer2.1.conv1','layer2.1.bn1'],\n",
    "    ['layer2.1.conv2','layer2.1.bn2','layer2.1.relu'],\n",
    "    ['layer3.0.conv1','layer3.0.bn1'],\n",
    "    ['layer3.0.conv2','layer3.0.bn2','layer3.0.relu'],\n",
    "    ['layer3.0.identity_downsample.0','layer3.0.identity_downsample.1'],\n",
    "    ['layer3.1.conv1','layer3.1.bn1'],\n",
    "    ['layer3.1.conv2','layer3.1.bn2','layer3.1.relu'],\n",
    "    ['layer4.0.conv1','layer4.0.bn1'],\n",
    "    ['layer4.0.conv2','layer4.0.bn2','layer4.0.relu'],\n",
    "    ['layer4.0.identity_downsample.0','layer4.0.identity_downsample.1'],\n",
    "    ['layer4.1.conv1','layer4.1.bn1'],\n",
    "    ['layer4.1.conv2','layer4.1.bn2','layer4.1.relu'],\n",
    "]\n",
    "\n",
    "dynamic_quant_model = torch.quantization.fuse_modules(dynamic_quant_model, modules_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'LinearPackedParams' object has no attribute '_modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfbgemm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m dynamic_quant_model\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mQConfig( \n\u001b[1;32m      3\u001b[0m             activation\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mdefault_observer,\n\u001b[1;32m      4\u001b[0m             weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mdefault_per_channel_weight_observer,\n\u001b[1;32m      5\u001b[0m         )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_quant_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:167\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(model, inplace, white_list, observer_non_leaf_module_list)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m    166\u001b[0m     model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[0;32m--> 167\u001b[0m \u001b[43mpropagate_qconfig_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# sanity check common API misusage\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mhasattr\u001b[39m(m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqconfig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m m\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodules()):\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:69\u001b[0m, in \u001b[0;36mpropagate_qconfig_\u001b[0;34m(module, qconfig_dict, white_list)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qconfig_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     qconfig_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 69\u001b[0m \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:49\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m---> 49\u001b[0m     \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmodule_qconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:49\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m---> 49\u001b[0m     \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmodule_qconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:47\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01min\u001b[39;00m white_list:\n\u001b[1;32m     46\u001b[0m     module\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m module_qconfig\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[1;32m     49\u001b[0m     _propagate_qconfig_helper(child, qconfig_dict, white_list,\n\u001b[1;32m     50\u001b[0m                               module_qconfig, module_prefix)\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/nn/modules/module.py:1183\u001b[0m, in \u001b[0;36mModule.named_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterator over immediate children modules, yielding both\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03mthe name of the module as well as the module itself.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \n\u001b[1;32m   1181\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m memo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m module \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m   1185\u001b[0m         memo\u001b[38;5;241m.\u001b[39madd(module)\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/nn/modules/module.py:771\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ModuleAttributeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'LinearPackedParams' object has no attribute '_modules'"
     ]
    }
   ],
   "source": [
    "backend = \"fbgemm\"\n",
    "dynamic_quant_model.qconfig = torch.quantization.QConfig( \n",
    "            activation=torch.quantization.default_observer,\n",
    "            weight=torch.quantization.default_per_channel_weight_observer,\n",
    "        )\n",
    "torch.quantization.prepare(dynamic_quant_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test(model, device, test_loader, criterion, quantize=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [\n",
    "    ['conv1','bn1','relu'],\n",
    "    ['layer1.0.conv1','layer1.0.bn1'],\n",
    "    ['layer1.0.conv2','layer1.0.bn2','layer1.0.relu'],\n",
    "    ['layer1.1.conv1','layer1.1.bn1'],\n",
    "    ['layer1.1.conv2','layer1.1.bn2','layer1.1.relu'],\n",
    "    ['layer2.0.conv1','layer2.0.bn1'],\n",
    "    ['layer2.0.conv2','layer2.0.bn2','layer2.0.relu'],\n",
    "    ['layer2.0.identity_downsample.0','layer2.0.identity_downsample.1'],\n",
    "    ['layer2.1.conv1','layer2.1.bn1'],\n",
    "    ['layer2.1.conv2','layer2.1.bn2','layer2.1.relu'],\n",
    "    ['layer3.0.conv1','layer3.0.bn1'],\n",
    "    ['layer3.0.conv2','layer3.0.bn2','layer3.0.relu'],\n",
    "    ['layer3.0.identity_downsample.0','layer3.0.identity_downsample.1'],\n",
    "    ['layer3.1.conv1','layer3.1.bn1'],\n",
    "    ['layer3.1.conv2','layer3.1.bn2','layer3.1.relu'],\n",
    "    ['layer4.0.conv1','layer4.0.bn1'],\n",
    "    ['layer4.0.conv2','layer4.0.bn2','layer4.0.relu'],\n",
    "    ['layer4.0.identity_downsample.0','layer4.0.identity_downsample.1'],\n",
    "    ['layer4.1.conv1','layer4.1.bn1'],\n",
    "    ['layer4.1.conv2','layer4.1.bn2','layer4.1.relu'],\n",
    "]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        print(model)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print('Size of the model After Static quantization')\n",
    "    print_size_of_model(model)\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'LinearPackedParams' object has no attribute '_modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_quant_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 32\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, criterion, quantize)\u001b[0m\n\u001b[1;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mfuse_modules(model, modules_to_fuse)\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mget_default_qconfig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfbgemm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:167\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(model, inplace, white_list, observer_non_leaf_module_list)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m    166\u001b[0m     model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[0;32m--> 167\u001b[0m \u001b[43mpropagate_qconfig_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# sanity check common API misusage\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mhasattr\u001b[39m(m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqconfig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m m\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodules()):\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:69\u001b[0m, in \u001b[0;36mpropagate_qconfig_\u001b[0;34m(module, qconfig_dict, white_list)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qconfig_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     qconfig_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 69\u001b[0m \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:49\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m---> 49\u001b[0m     \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmodule_qconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:49\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m---> 49\u001b[0m     \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhite_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmodule_qconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/quantization/quantize.py:47\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[0;34m(module, qconfig_dict, white_list, qconfig_parent, prefix)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01min\u001b[39;00m white_list:\n\u001b[1;32m     46\u001b[0m     module\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m module_qconfig\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     48\u001b[0m     module_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[1;32m     49\u001b[0m     _propagate_qconfig_helper(child, qconfig_dict, white_list,\n\u001b[1;32m     50\u001b[0m                               module_qconfig, module_prefix)\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/nn/modules/module.py:1183\u001b[0m, in \u001b[0;36mModule.named_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterator over immediate children modules, yielding both\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03mthe name of the module as well as the module itself.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \n\u001b[1;32m   1181\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m memo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m module \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m   1185\u001b[0m         memo\u001b[38;5;241m.\u001b[39madd(module)\n",
      "File \u001b[0;32m~/task1/lib/python3.8/site-packages/torch/nn/modules/module.py:771\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ModuleAttributeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'LinearPackedParams' object has no attribute '_modules'"
     ]
    }
   ],
   "source": [
    "test(dynamic_quant_model,device,testloader,criterion=nn.CrossEntropyLoss(),quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import helper_functions\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=16, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero parameters : 11232612\n",
      "The number of zero parameters : 4800\n"
     ]
    }
   ],
   "source": [
    "helper_functions.count_nonzero_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
