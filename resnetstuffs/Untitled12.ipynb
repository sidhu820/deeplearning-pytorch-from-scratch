{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpsKHbAeeD_u",
        "outputId": "4c67fb9b-4549-4463-c3ba-e3f76818fc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121 0.18.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models.quantization as models\n",
        "from timeit import default_timer as timer\n",
        "import torchsummary\n",
        "print(torch.__version__ , torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "y7NiDbNKeILS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=16, pin_memory= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Z9hElReKfw",
        "outputId": "55a13734-b1e0-4990-d922-70c885b43932"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 39063810.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9TDEGwueM4D",
        "outputId": "11a83b5d-e154-44c4-a67c-c2d725d798a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUR7abXCePde",
        "outputId": "4aff8d2e-df7d-4726-8d32-fb27dd67c8eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, identity_downsample= None, stride= 1):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size= 3, stride= stride, padding= 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size= 3,padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace= True)\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.skip_add = nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        # x = self.relu(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        # x += identity\n",
        "        x = self.skip_add.add(x, identity)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, BasicBlock, layers, image_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size= 7, stride= 2, padding= 3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace= True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride= 2, padding= 1)\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, layers[0], out_channels= 64, stride= 1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, layers[1], out_channels= 128, stride= 2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, layers[2], out_channels= 256, stride= 2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, layers[3], out_channels= 512, stride= 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.dequant(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self, BasicBlock, num_residual_blocks, out_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "        if stride != 1 or self.in_channels != out_channels:\n",
        "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels , kernel_size= 1, stride= stride),\n",
        "                                               nn.BatchNorm2d(out_channels))\n",
        "        layers.append(BasicBlock(self.in_channels, out_channels, identity_downsample, stride))\n",
        "        self.in_channels = out_channels\n",
        "\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet18(img_channels= 3, num_classes= 10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], img_channels, num_classes)\n"
      ],
      "metadata": {
        "id": "raU25m8geRkE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18().to(device)"
      ],
      "metadata": {
        "id": "Fy4l2KgjeTbN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(model, input_size= (3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdLqW2WNeXkf",
        "outputId": "092ba74f-370b-4c11-e531-6bcfec2d01cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         QuantStub-1          [-1, 3, 224, 224]               0\n",
            "            Conv2d-2         [-1, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
            "              ReLU-4         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
            "            Conv2d-6           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
            "              ReLU-8           [-1, 64, 56, 56]               0\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "         Identity-11           [-1, 64, 56, 56]               0\n",
            "             ReLU-12           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-13           [-1, 64, 56, 56]               0\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "             ReLU-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "         Identity-19           [-1, 64, 56, 56]               0\n",
            "             ReLU-20           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]          73,856\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "             ReLU-24          [-1, 128, 28, 28]               0\n",
            "           Conv2d-25          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
            "           Conv2d-27          [-1, 128, 28, 28]           8,320\n",
            "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
            "         Identity-29          [-1, 128, 28, 28]               0\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-31          [-1, 128, 28, 28]               0\n",
            "           Conv2d-32          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
            "             ReLU-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
            "         Identity-37          [-1, 128, 28, 28]               0\n",
            "             ReLU-38          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-39          [-1, 128, 28, 28]               0\n",
            "           Conv2d-40          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "           Conv2d-43          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-44          [-1, 256, 14, 14]             512\n",
            "           Conv2d-45          [-1, 256, 14, 14]          33,024\n",
            "      BatchNorm2d-46          [-1, 256, 14, 14]             512\n",
            "         Identity-47          [-1, 256, 14, 14]               0\n",
            "             ReLU-48          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-49          [-1, 256, 14, 14]               0\n",
            "           Conv2d-50          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-51          [-1, 256, 14, 14]             512\n",
            "             ReLU-52          [-1, 256, 14, 14]               0\n",
            "           Conv2d-53          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-54          [-1, 256, 14, 14]             512\n",
            "         Identity-55          [-1, 256, 14, 14]               0\n",
            "             ReLU-56          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-57          [-1, 256, 14, 14]               0\n",
            "           Conv2d-58            [-1, 512, 7, 7]       1,180,160\n",
            "      BatchNorm2d-59            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-60            [-1, 512, 7, 7]               0\n",
            "           Conv2d-61            [-1, 512, 7, 7]       2,359,808\n",
            "      BatchNorm2d-62            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-63            [-1, 512, 7, 7]         131,584\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "         Identity-65            [-1, 512, 7, 7]               0\n",
            "             ReLU-66            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-67            [-1, 512, 7, 7]               0\n",
            "           Conv2d-68            [-1, 512, 7, 7]       2,359,808\n",
            "      BatchNorm2d-69            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-70            [-1, 512, 7, 7]               0\n",
            "           Conv2d-71            [-1, 512, 7, 7]       2,359,808\n",
            "      BatchNorm2d-72            [-1, 512, 7, 7]           1,024\n",
            "         Identity-73            [-1, 512, 7, 7]               0\n",
            "             ReLU-74            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-75            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-76            [-1, 512, 1, 1]               0\n",
            "      DeQuantStub-77            [-1, 512, 1, 1]               0\n",
            "           Linear-78                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,186,442\n",
            "Trainable params: 11,186,442\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 69.68\n",
            "Params size (MB): 42.67\n",
            "Estimated Total Size (MB): 112.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, epochs, device):\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "  epochs = epochs\n",
        "  for epoch in range(epochs):\n",
        "      running_loss = 0.0\n",
        "      model.train()\n",
        "      for i, data in enumerate(dataloader, 0):\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          model = model.to(device)\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')"
      ],
      "metadata": {
        "id": "zVGbNWJkeZUt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, trainloader, 20, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVqDBMSSehaZ",
        "outputId": "bccaa980-a32d-47a0-9c40-1c6654828cef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3927033524531538\n",
            "Epoch 2, Loss: 0.9391593761608729\n",
            "Epoch 3, Loss: 0.7156124243041133\n",
            "Epoch 4, Loss: 0.5588296863352856\n",
            "Epoch 5, Loss: 0.4368115037184237\n",
            "Epoch 6, Loss: 0.32606637628410784\n",
            "Epoch 7, Loss: 0.2299094204135868\n",
            "Epoch 8, Loss: 0.14693323283187112\n",
            "Epoch 9, Loss: 0.08242665890537565\n",
            "Epoch 10, Loss: 0.04395271269777251\n",
            "Epoch 11, Loss: 0.0288875606170048\n",
            "Epoch 12, Loss: 0.01118597659595606\n",
            "Epoch 13, Loss: 0.006925020730518915\n",
            "Epoch 14, Loss: 0.006184484288001152\n",
            "Epoch 15, Loss: 0.0023637948982159146\n",
            "Epoch 16, Loss: 0.002377648723347153\n",
            "Epoch 17, Loss: 0.0015287184554850087\n",
            "Epoch 18, Loss: 0.0011677792675391524\n",
            "Epoch 19, Loss: 0.001218618072193179\n",
            "Epoch 20, Loss: 0.0010378004425479804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time(start:float, end : float, device : torch.device = None):\n",
        "    total_time = end - start\n",
        "    print(f' Evaluation time :{total_time:.3f}')"
      ],
      "metadata": {
        "id": "jqaaCNsDemKh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, device):\n",
        "  start = timer()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          model = model.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "      print(f'Accuracy of the network on the {total} test images: %d %%' % (100 * correct / total))\n",
        "  end = timer()\n",
        "  calculate_time(start, end, device)"
      ],
      "metadata": {
        "id": "EV_xI4v7exF7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, testloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYeRsiY_e84K",
        "outputId": "701112be-362e-4fb9-884b-4d1fb0d659ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n",
            " Evaluation time :20.562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def print_memory_usage():\n",
        "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
        "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
        "\n",
        "# Call this function before and after model testing\n"
      ],
      "metadata": {
        "id": "kXhcDFxHe_zc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_memory_usage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b562KZ_vrqIB",
        "outputId": "94033a60-21e7-4482-92a2-7572cef8ccd2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated memory: 108.033024 MB\n",
            "Cached memory: 2107.63776 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7hocaj_rt_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}