{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106f85e-0e5e-4bd0-93b9-a63bae047ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models.quantization as models\n",
    "import torch.nn.utils.prune as prune\n",
    "import os\n",
    "import copy\n",
    "import torchsummary\n",
    "import help\n",
    "from help import helper_functions\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e0a831-18d3-41a7-96f9-5e4acd426290",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ecf338-074d-49ec-9b05-c14ea1d85e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=16, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d2d6ec-aca8-467a-9eb8-a71932441e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623a92b6-c30c-47aa-aca1-0c4beaf86628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample= None, stride= 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.expansion = 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size= 3, stride= stride, padding= 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size= 3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        # x += identity\n",
    "        x = self.skip_add.add(x, identity)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, BasicBlock, layers, image_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size= 7, stride= 2, padding= 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride= 2, padding= 1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, layers[0], out_channels= 64, stride= 1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, layers[1], out_channels= 128, stride= 2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, layers[2], out_channels= 256, stride= 2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, layers[3], out_channels= 512, stride= 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_layer(self, BasicBlock, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels , kernel_size= 1, stride= stride),\n",
    "                                               nn.BatchNorm2d(out_channels))\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet18(img_channels= 3, num_classes= 10):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], img_channels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ea4d9a-5930-4c33-8ae5-333e731d974f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55825775-41bd-465f-8405-3f74c43baf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero parameters : 11186442\n",
      "The number of zero parameters : 4800\n"
     ]
    }
   ],
   "source": [
    "helper_functions.count_nonzero_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a53232-e942-442f-9863-3beff18e4460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('resnet_with_10_class.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d91f0b2-ef1a-492d-8ef7-06074b299d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero parameters : 11186442\n",
      "The number of zero parameters : 1117203\n"
     ]
    }
   ],
   "source": [
    "helper_functions.count_nonzero_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da12770-1736-4f0f-8264-32491742e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n",
      " Evaluation time :400.715\n"
     ]
    }
   ],
   "source": [
    "helper_functions.test(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3673a709-46eb-4141-a7e8-71cd95da016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size (KB) : 44830.348\n"
     ]
    }
   ],
   "source": [
    "helper_functions.print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b631bcb-e82a-4ac6-a47a-0cd858edf1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "modules_to_fuse = [\n",
    "    ['conv1', 'bn1', 'relu'],\n",
    "    ['layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu'],\n",
    "    ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "    ['layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu'],\n",
    "    ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "    ['layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu'],\n",
    "    ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "    ['layer2.0.identity_downsample.0', 'layer2.0.identity_downsample.1'],\n",
    "    ['layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu'],\n",
    "    ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "    ['layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu'],\n",
    "    ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "    ['layer3.0.identity_downsample.0', 'layer3.0.identity_downsample.1'],\n",
    "    ['layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu'],\n",
    "    ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "    ['layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu'],\n",
    "    ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "    ['layer4.0.identity_downsample.0', 'layer4.0.identity_downsample.1'],\n",
    "    ['layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu'],\n",
    "    ['layer4.1.conv2', 'layer4.1.bn2'],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model = torch.quantization.fuse_modules(model, modules_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "978bcfb8-586a-4d74-94c7-deff429af107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dynamic_quantized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.qconfig = torch.quantization.default_qconfig\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = torch.quantization.prepare(model, inplace=True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqnnpack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdynamic_quantized\u001b[49m\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mget_default_qconfig(backend)\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mquantized\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m backend\n\u001b[1;32m      6\u001b[0m static_quantized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mprepare(dynamic_quantized, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dynamic_quantized' is not defined"
     ]
    }
   ],
   "source": [
    "# model.qconfig = torch.quantization.default_qconfig\n",
    "# model = torch.quantization.prepare(model, inplace=True)\n",
    "backend = \"qnnpack\"\n",
    "dynamic_quantized.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "static_quantized = torch.quantization.prepare(dynamic_quantized, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b584425-d519-4c3e-9f8e-12eb6416efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_data = helper_functions.slice_dataloader(testloader, 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5b846-1777-4d0c-9631-69705d4d62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.caliberate(model,small_test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1dca1e-9820-41da-a806-5ede9911843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1a606-715f-44b2-8ce5-99f5d68ff14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.test(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb207a-ddef-4ee0-b265-e348c67232ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee3c37-b29b-4577-a4ef-297b61d5861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Load the serialized model from file\n",
    "# # # import io\n",
    "# # # with open('quantized_model.pt', 'rb') as f:\n",
    "# # #     b = f.read()\n",
    "\n",
    "# # # Load the model from the serialized bytes\n",
    "# # # scripted_quantized = torch.jit.load(io.BytesIO(serialized_bytes))\n",
    "# # # b = 'model.pth'\n",
    "# # # b.seek(0)\n",
    "# # # model.load_state_dict(torch.git.load('model.pth', map_location='cpu')\n",
    "# mq = torch.jit.load(\"quant_model.pth\")\n",
    "# print(mq)\n",
    "# input_tensor = torch.randn(1, 3, 224, 224)  # Example input tensor\n",
    "# output = mq(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62470fac-6a54-4096-a68f-bb849cc98042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = ResNet18()\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to('cpu')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ab2db-370d-4c68-b168-b7f9caa1ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'jitmodelfile.pth' \n",
    "model = load_model(modelfile).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133bf78-676f-4591-acc8-4e3621d4a7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (task1)",
   "language": "python",
   "name": "task1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
