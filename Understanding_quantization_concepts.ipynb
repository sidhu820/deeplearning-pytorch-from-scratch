{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be63720a-b12f-4a8b-bc06-76b7a453964d",
   "metadata": {},
   "source": [
    "## Understanding the concepts of Quantizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef64d75-85b5-48ab-b726-89f27531e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c10e01c-6113-4917-b55b-2a1c41c90916",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root= './data', train= True, download= True, transform= transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size= 20, shuffle= True)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root= './data', train= False, download= True, transform= transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size= 10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65574497-ee75-4f90-a0cd-68bdf93e92fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_trainset), len(mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a42a917-9904-43f4-b379-c0bfe6292aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e13b9c-3170-436b-9caf-06422079db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1 = 100, hidden_size_2= 100):\n",
    "        super(VerySimpleNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24598c56-3633-4d73-b16d-5b0cf3e8e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VerySimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1277f0e-ed8a-440d-9e00-e5d720729958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs= 5, total_iteration_limit= None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr= 0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        loss_sum = 0\n",
    "        num_iteration = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc= f'epoch {epoch+1}')\n",
    "        if total_iteration_limit is not None:\n",
    "            data_iterator.total = total_iteration_limit\n",
    "        for data in data_iterator:\n",
    "            num_iteration += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iteration\n",
    "            data_iterator.set_postfix(loss = avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iteration_limit is not None and total_iterations >= total_iteration_limit:\n",
    "                return\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('size (KB) :',os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print(\"loaded model from disk\")\n",
    "\n",
    "else :\n",
    "    train(train_loader, net, epochs= 5)\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d8a3ac-ade6-4eaa-8a97-1eab1f25e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, total_iterations: int = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    iterations = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for data in tqdm(test_loader, desc= \"testing\"):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy : {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a469b630-e60c-4b9b-8d14-d39e7109461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights before quantization \n",
      "Parameter containing:\n",
      "tensor([[ 0.0607,  0.0424,  0.0059,  ...,  0.0174,  0.0488,  0.0213],\n",
      "        [-0.0083,  0.0153,  0.0304,  ...,  0.0152,  0.0430,  0.0030],\n",
      "        [ 0.0363,  0.0573,  0.0394,  ...,  0.0461,  0.0401,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0441,  0.0173,  0.0452,  ...,  0.0729,  0.0238,  0.0820],\n",
      "        [ 0.0039,  0.0593,  0.0658,  ...,  0.0267, -0.0009,  0.0061],\n",
      "        [ 0.0490,  0.0488,  0.0113,  ...,  0.0463,  0.0136,  0.0208]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print('weights before quantization ')\n",
    "print(net.linear1.weight)\n",
    "print(net.linear1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc3cd3c-7e88-46d1-897b-0f6f58daac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the model before quantisation\n",
      "size (KB) : 360.998\n"
     ]
    }
   ],
   "source": [
    "print(\"size of the model before quantisation\")\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1af97c0-13c7-4bc3-bc29-152224d34f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model before quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 444.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of model before quantization\")\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca440d2-255e-4b1a-b321-a451b33e55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedVerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1= 100, hidden_size_2= 100):\n",
    "        super(QuantizedVerySimpleNet, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9cbc34-948a-4b36-bdd4-b3714cfb4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedVerySimpleNet(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_quantised = QuantizedVerySimpleNet().to(device)\n",
    "\n",
    "net_quantised.load_state_dict(net.state_dict())\n",
    "net_quantised.eval()\n",
    "\n",
    "net_quantised.qconfig = torch.ao.quantization.default_qconfig\n",
    "net_quantised = torch.ao.quantization.prepare(net_quantised)\n",
    "net_quantised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f59647f7-3a9e-4b09-87e3-ed65a3d656ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 340.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(net_quantised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b241b18a-851f-4de5-98d2-a52db596ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check statistics of various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedVerySimpleNet(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-65.33385467529297, max_val=34.708717346191406)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-47.84341812133789, max_val=32.8056640625)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-57.502113342285156, max_val=31.2893123626709)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"check statistics of various layers\")\n",
    "net_quantised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb981bf0-ab7b-4745-8d42-933012f8ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_quantised = torch.ao.quantization.convert(net_quantised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217226dd-cc1e-428c-9abb-09c9c5ef7b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics of various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedVerySimpleNet(\n",
       "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
       "  (linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.7877367734909058, zero_point=83, qscheme=torch.per_tensor_affine)\n",
       "  (linear2): QuantizedLinear(in_features=100, out_features=100, scale=0.6350321173667908, zero_point=75, qscheme=torch.per_tensor_affine)\n",
       "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.6991450786590576, zero_point=82, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"statistics of various layers\")\n",
    "net_quantised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9437c4-6762-4f28-b41b-ae817ebbdda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after the quantization\n",
      "tensor([[ 8,  6,  1,  ...,  2,  7,  3],\n",
      "        [-1,  2,  4,  ...,  2,  6,  0],\n",
      "        [ 5,  8,  5,  ...,  6,  6,  1],\n",
      "        ...,\n",
      "        [ 6,  2,  6,  ..., 10,  3, 11],\n",
      "        [ 1,  8,  9,  ...,  4,  0,  1],\n",
      "        [ 7,  7,  2,  ...,  6,  2,  3]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(\"weights after the quantization\")\n",
    "print(torch.int_repr(net_quantised.linear1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d02cc7-ba3f-4450-9d2d-be588d68e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal weight :\n",
      "Parameter containing:\n",
      "tensor([[ 0.0607,  0.0424,  0.0059,  ...,  0.0174,  0.0488,  0.0213],\n",
      "        [-0.0083,  0.0153,  0.0304,  ...,  0.0152,  0.0430,  0.0030],\n",
      "        [ 0.0363,  0.0573,  0.0394,  ...,  0.0461,  0.0401,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0441,  0.0173,  0.0452,  ...,  0.0729,  0.0238,  0.0820],\n",
      "        [ 0.0039,  0.0593,  0.0658,  ...,  0.0267, -0.0009,  0.0061],\n",
      "        [ 0.0490,  0.0488,  0.0113,  ...,  0.0463,  0.0136,  0.0208]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Dequantized weights\n",
      "tensor([[ 0.0574,  0.0431,  0.0072,  ...,  0.0144,  0.0502,  0.0215],\n",
      "        [-0.0072,  0.0144,  0.0287,  ...,  0.0144,  0.0431,  0.0000],\n",
      "        [ 0.0359,  0.0574,  0.0359,  ...,  0.0431,  0.0431,  0.0072],\n",
      "        ...,\n",
      "        [ 0.0431,  0.0144,  0.0431,  ...,  0.0718,  0.0215,  0.0789],\n",
      "        [ 0.0072,  0.0574,  0.0646,  ...,  0.0287,  0.0000,  0.0072],\n",
      "        [ 0.0502,  0.0502,  0.0144,  ...,  0.0431,  0.0144,  0.0215]])\n"
     ]
    }
   ],
   "source": [
    "print(\"orginal weight :\")\n",
    "print(net.linear1.weight)\n",
    "print()\n",
    "print(\"Dequantized weights\")\n",
    "print(torch.dequantize(net_quantised.linear1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd26c2a8-fe1c-46bb-b102-fb2eb0a61168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of model after quantization\n",
      "size (KB) : 95.394\n"
     ]
    }
   ],
   "source": [
    "print(\"size of model after quantization\")\n",
    "print_size_of_model(net_quantised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aca37aa9-1722-441f-8145-a65bfa220ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 394.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing model after quantization\")\n",
    "test(net_quantised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (task1)",
   "language": "python",
   "name": "task1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
